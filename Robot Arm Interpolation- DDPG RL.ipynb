{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robot Arm Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    An Environment of a small ball(box) and a robot arm of two* joints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyglet\n",
    "\n",
    "\n",
    "class ArmEnv(object):\n",
    "    viewer = None\n",
    "    dt = .1    # refresh rate\n",
    "    action_bound = [-1, 1]\n",
    "    goal = {'x': 100., 'y': 100., 'l': 40}\n",
    "    state_dim = 9\n",
    "    action_dim = 2\n",
    "\n",
    "    def __init__(self):\n",
    "        self.arm_info = np.zeros(\n",
    "            2, dtype=[('l', np.float32), ('r', np.float32)])\n",
    "        self.arm_info['l'] = 100        # 2 arms length\n",
    "        self.arm_info['r'] = np.pi/6    # 2 angles information\n",
    "        self.on_goal = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        action = np.clip(action, *self.action_bound)\n",
    "        self.arm_info['r'] += action * self.dt\n",
    "        self.arm_info['r'] %= np.pi * 2    # normalize\n",
    "\n",
    "        (a1l, a2l) = self.arm_info['l']  # radius, arm length\n",
    "        (a1r, a2r) = self.arm_info['r']  # radian, angle\n",
    "        a1xy = np.array([200., 200.])    # a1 start (x0, y0)\n",
    "        a1xy_ = np.array([np.cos(a1r), np.sin(a1r)]) * a1l + a1xy  # a1 end and a2 start (x1, y1)\n",
    "        finger = np.array([np.cos(a1r + a2r), np.sin(a1r + a2r)]) * a2l + a1xy_  # a2 end (x2, y2)\n",
    "        # normalize features\n",
    "        dist1 = [(self.goal['x'] - a1xy_[0]) / 400, (self.goal['y'] - a1xy_[1]) / 400]\n",
    "        dist2 = [(self.goal['x'] - finger[0]) / 400, (self.goal['y'] - finger[1]) / 400]\n",
    "        r = -np.sqrt(dist2[0]**2+dist2[1]**2)\n",
    "\n",
    "        # done and reward\n",
    "        if self.goal['x'] - self.goal['l']/2 < finger[0] < self.goal['x'] + self.goal['l']/2:\n",
    "            if self.goal['y'] - self.goal['l']/2 < finger[1] < self.goal['y'] + self.goal['l']/2:\n",
    "                r += 1.\n",
    "                self.on_goal += 1\n",
    "                if self.on_goal > 50:\n",
    "                    done = True\n",
    "        else:\n",
    "            self.on_goal = 0\n",
    "\n",
    "        # state\n",
    "        s = np.concatenate((a1xy_/200, finger/200, dist1 + dist2, [1. if self.on_goal else 0.]))\n",
    "        return s, r, done\n",
    "\n",
    "    def reset(self):\n",
    "        self.goal['x'] = np.random.rand()*400.\n",
    "        self.goal['y'] = np.random.rand()*400.\n",
    "        self.arm_info['r'] = 2 * np.pi * np.random.rand(2)\n",
    "        self.on_goal = 0\n",
    "        (a1l, a2l) = self.arm_info['l']  # radius, arm length\n",
    "        (a1r, a2r) = self.arm_info['r']  # radian, angle\n",
    "        a1xy = np.array([200., 200.])  # a1 start (x0, y0)\n",
    "        a1xy_ = np.array([np.cos(a1r), np.sin(a1r)]) * a1l + a1xy  # a1 end and a2 start (x1, y1)\n",
    "        finger = np.array([np.cos(a1r + a2r), np.sin(a1r + a2r)]) * a2l + a1xy_  # a2 end (x2, y2)\n",
    "        # normalize features\n",
    "        dist1 = [(self.goal['x'] - a1xy_[0])/400, (self.goal['y'] - a1xy_[1])/400]\n",
    "        dist2 = [(self.goal['x'] - finger[0])/400, (self.goal['y'] - finger[1])/400]\n",
    "        # state\n",
    "        s = np.concatenate((a1xy_/200, finger/200, dist1 + dist2, [1. if self.on_goal else 0.]))\n",
    "        return s\n",
    "\n",
    "    def render(self):\n",
    "        if self.viewer is None:\n",
    "            self.viewer = Viewer(self.arm_info, self.goal)\n",
    "        self.viewer.render()\n",
    "\n",
    "    def sample_action(self):\n",
    "        return np.random.rand(2)-0.5    # two radians\n",
    "\n",
    "\n",
    "class Viewer(pyglet.window.Window):\n",
    "    bar_thc = 5\n",
    "\n",
    "    def __init__(self, arm_info, goal):\n",
    "        # vsync=False to not use the monitor FPS, we can speed up training\n",
    "        super(Viewer, self).__init__(width=400, height=400, resizable=False, caption='Arm', vsync=False)\n",
    "        pyglet.gl.glClearColor(1, 1, 1, 1)\n",
    "        self.arm_info = arm_info\n",
    "        self.goal_info = goal\n",
    "        self.center_coord = np.array([200, 200])\n",
    "\n",
    "        self.batch = pyglet.graphics.Batch()    # display whole batch at once\n",
    "        self.goal = self.batch.add(\n",
    "            4, pyglet.gl.GL_QUADS, None,    # 4 corners\n",
    "            ('v2f', [goal['x'] - goal['l'] / 2, goal['y'] - goal['l'] / 2,                # location\n",
    "                     goal['x'] - goal['l'] / 2, goal['y'] + goal['l'] / 2,\n",
    "                     goal['x'] + goal['l'] / 2, goal['y'] + goal['l'] / 2,\n",
    "                     goal['x'] + goal['l'] / 2, goal['y'] - goal['l'] / 2]),\n",
    "            ('c3B', (86, 109, 249) * 4))    # color\n",
    "        self.arm1 = self.batch.add(\n",
    "            4, pyglet.gl.GL_QUADS, None,\n",
    "            ('v2f', [250, 250,                # location\n",
    "                     250, 300,\n",
    "                     260, 300,\n",
    "                     260, 250]),\n",
    "            ('c3B', (249, 86, 86) * 4,))    # color\n",
    "        self.arm2 = self.batch.add(\n",
    "            4, pyglet.gl.GL_QUADS, None,\n",
    "            ('v2f', [100, 150,              # location\n",
    "                     100, 160,\n",
    "                     200, 160,\n",
    "                     200, 150]), ('c3B', (249, 86, 86) * 4,))\n",
    "\n",
    "    def render(self):\n",
    "        self._update_arm()\n",
    "        self.switch_to()\n",
    "        self.dispatch_events()\n",
    "        self.dispatch_event('on_draw')\n",
    "        self.flip()\n",
    "\n",
    "    def on_draw(self):\n",
    "        self.clear()\n",
    "        self.batch.draw()\n",
    "\n",
    "    def _update_arm(self):\n",
    "        # update goal\n",
    "        self.goal.vertices = (\n",
    "            self.goal_info['x'] - self.goal_info['l']/2, self.goal_info['y'] - self.goal_info['l']/2,\n",
    "            self.goal_info['x'] + self.goal_info['l']/2, self.goal_info['y'] - self.goal_info['l']/2,\n",
    "            self.goal_info['x'] + self.goal_info['l']/2, self.goal_info['y'] + self.goal_info['l']/2,\n",
    "            self.goal_info['x'] - self.goal_info['l']/2, self.goal_info['y'] + self.goal_info['l']/2)\n",
    "\n",
    "        # update arm\n",
    "        (a1l, a2l) = self.arm_info['l']     # radius, arm length\n",
    "        (a1r, a2r) = self.arm_info['r']     # radian, angle\n",
    "        a1xy = self.center_coord            # a1 start (x0, y0)\n",
    "        a1xy_ = np.array([np.cos(a1r), np.sin(a1r)]) * a1l + a1xy   # a1 end and a2 start (x1, y1)\n",
    "        a2xy_ = np.array([np.cos(a1r+a2r), np.sin(a1r+a2r)]) * a2l + a1xy_  # a2 end (x2, y2)\n",
    "\n",
    "        a1tr, a2tr = np.pi / 2 - self.arm_info['r'][0], np.pi / 2 - self.arm_info['r'].sum()\n",
    "        xy01 = a1xy + np.array([-np.cos(a1tr), np.sin(a1tr)]) * self.bar_thc\n",
    "        xy02 = a1xy + np.array([np.cos(a1tr), -np.sin(a1tr)]) * self.bar_thc\n",
    "        xy11 = a1xy_ + np.array([np.cos(a1tr), -np.sin(a1tr)]) * self.bar_thc\n",
    "        xy12 = a1xy_ + np.array([-np.cos(a1tr), np.sin(a1tr)]) * self.bar_thc\n",
    "\n",
    "        xy11_ = a1xy_ + np.array([np.cos(a2tr), -np.sin(a2tr)]) * self.bar_thc\n",
    "        xy12_ = a1xy_ + np.array([-np.cos(a2tr), np.sin(a2tr)]) * self.bar_thc\n",
    "        xy21 = a2xy_ + np.array([-np.cos(a2tr), np.sin(a2tr)]) * self.bar_thc\n",
    "        xy22 = a2xy_ + np.array([np.cos(a2tr), -np.sin(a2tr)]) * self.bar_thc\n",
    "\n",
    "        self.arm1.vertices = np.concatenate((xy01, xy02, xy11, xy12))\n",
    "        self.arm2.vertices = np.concatenate((xy11_, xy12_, xy21, xy22))\n",
    "\n",
    "    # convert the mouse coordinate to goal's coordinate\n",
    "    def on_mouse_motion(self, x, y, dx, dy):\n",
    "        self.goal_info['x'] = x\n",
    "        self.goal_info['y'] = y\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     Teaching a robot arm to reach a ball(box) when placed anywhere around in the vicinity of environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-e0c6b6993ff9>:84: dense (from tensorflow.python.keras.legacy_tf_layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Rohit\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import numpy as np\n",
    "\n",
    "#####################  hyper parameters  ####################\n",
    "\n",
    "LR_A = 0.001    # learning rate for actor\n",
    "LR_C = 0.001    # learning rate for critic\n",
    "GAMMA = 0.9     # reward discount\n",
    "TAU = 0.01      # soft replacement\n",
    "MEMORY_CAPACITY = 30000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "class DDPG(object):\n",
    "    def __init__(self, a_dim, s_dim, a_bound,):\n",
    "        self.memory = np.zeros((MEMORY_CAPACITY, s_dim * 2 + a_dim + 1), dtype=np.float32)\n",
    "        self.pointer = 0\n",
    "        self.memory_full = False\n",
    "        self.sess = tf.compat.v1.Session()\n",
    "        self.a_replace_counter, self.c_replace_counter = 0, 0\n",
    "\n",
    "        self.a_dim, self.s_dim, self.a_bound = a_dim, s_dim, a_bound[1]\n",
    "        self.S = tf.compat.v1.placeholder(tf.float32, [None, s_dim], 's')\n",
    "        self.S_ = tf.compat.v1.placeholder(tf.float32, [None, s_dim], 's_')\n",
    "        self.R = tf.compat.v1.placeholder(tf.float32, [None, 1], 'r')\n",
    "\n",
    "        with tf.compat.v1.variable_scope('Actor'):\n",
    "            self.a = self._build_a(self.S, scope='eval', trainable=True)\n",
    "            a_ = self._build_a(self.S_, scope='target', trainable=False)\n",
    "        with tf.compat.v1.variable_scope('Critic'):\n",
    "            # assign self.a = a in memory when calculating q for td_error,\n",
    "            # otherwise the self.a is from Actor when updating Actor\n",
    "            q = self._build_c(self.S, self.a, scope='eval', trainable=True)\n",
    "            q_ = self._build_c(self.S_, a_, scope='target', trainable=False)\n",
    "\n",
    "        # networks parameters\n",
    "        self.ae_params = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.GLOBAL_VARIABLES, scope='Actor/eval')\n",
    "        self.at_params = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.GLOBAL_VARIABLES, scope='Actor/target')\n",
    "        self.ce_params = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.GLOBAL_VARIABLES, scope='Critic/eval')\n",
    "        self.ct_params = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.GLOBAL_VARIABLES, scope='Critic/target')\n",
    "\n",
    "        # target net replacement\n",
    "        self.soft_replace = [[tf.compat.v1.assign(ta, (1 - TAU) * ta + TAU * ea), tf.compat.v1.assign(tc, (1 - TAU) * tc + TAU * ec)]\n",
    "                             for ta, ea, tc, ec in zip(self.at_params, self.ae_params, self.ct_params, self.ce_params)]\n",
    "\n",
    "        q_target = self.R + GAMMA * q_\n",
    "        # in the feed_dic for the td_error, the self.a should change to actions in memory\n",
    "        td_error = tf.compat.v1.losses.mean_squared_error(labels=q_target, predictions=q)\n",
    "        self.ctrain = tf.compat.v1.train.AdamOptimizer(LR_C).minimize(td_error, var_list=self.ce_params)\n",
    "\n",
    "        a_loss = - tf.reduce_mean(input_tensor=q)    # maximize the q\n",
    "        self.atrain = tf.compat.v1.train.AdamOptimizer(LR_A).minimize(a_loss, var_list=self.ae_params)\n",
    "\n",
    "        self.sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "    def choose_action(self, s):\n",
    "        return self.sess.run(self.a, {self.S: s[None, :]})[0]\n",
    "\n",
    "    def learn(self):\n",
    "        # soft target replacement\n",
    "        self.sess.run(self.soft_replace)\n",
    "\n",
    "        indices = np.random.choice(MEMORY_CAPACITY, size=BATCH_SIZE)\n",
    "        bt = self.memory[indices, :]\n",
    "        bs = bt[:, :self.s_dim]\n",
    "        ba = bt[:, self.s_dim: self.s_dim + self.a_dim]\n",
    "        br = bt[:, -self.s_dim - 1: -self.s_dim]\n",
    "        bs_ = bt[:, -self.s_dim:]\n",
    "\n",
    "        self.sess.run(self.atrain, {self.S: bs})\n",
    "        self.sess.run(self.ctrain, {self.S: bs, self.a: ba, self.R: br, self.S_: bs_})\n",
    "\n",
    "    def store_transition(self, s, a, r, s_):\n",
    "        transition = np.hstack((s, a, [r], s_))\n",
    "        index = self.pointer % MEMORY_CAPACITY  # replace the old memory with new memory\n",
    "        self.memory[index, :] = transition\n",
    "        self.pointer += 1\n",
    "        if self.pointer > MEMORY_CAPACITY:      # indicator for learning\n",
    "            self.memory_full = True\n",
    "\n",
    "    def _build_a(self, s, scope, trainable):\n",
    "        with tf.compat.v1.variable_scope(scope):\n",
    "            net = tf.compat.v1.layers.dense(s, 300, activation=tf.nn.relu, name='l1', trainable=trainable)\n",
    "            a = tf.compat.v1.layers.dense(net, self.a_dim, activation=tf.nn.tanh, name='a', trainable=trainable)\n",
    "            return tf.multiply(a, self.a_bound, name='scaled_a')\n",
    "\n",
    "    def _build_c(self, s, a, scope, trainable):\n",
    "        with tf.compat.v1.variable_scope(scope):\n",
    "            n_l1 = 300\n",
    "            w1_s = tf.compat.v1.get_variable('w1_s', [self.s_dim, n_l1], trainable=trainable)\n",
    "            w1_a = tf.compat.v1.get_variable('w1_a', [self.a_dim, n_l1], trainable=trainable)\n",
    "            b1 = tf.compat.v1.get_variable('b1', [1, n_l1], trainable=trainable)\n",
    "            net = tf.nn.relu(tf.matmul(s, w1_s) + tf.matmul(a, w1_a) + b1)\n",
    "            return tf.compat.v1.layers.dense(net, 1, trainable=trainable)  # Q(s,a)\n",
    "\n",
    "    def save(self):\n",
    "        saver = tf.compat.v1.train.Saver()\n",
    "        saver.save(self.sess, './params', write_meta_graph=False)\n",
    "\n",
    "    def restore(self):\n",
    "        saver = tf.compat.v1.train.Saver()\n",
    "        saver.restore(self.sess, './params')\n",
    "\n",
    "## MAIN\n",
    "\n",
    "MAX_EPISODES = 600\n",
    "MAX_EP_STEPS = 350\n",
    "ON_TRAIN = True\n",
    "\n",
    "# set env\n",
    "env = ArmEnv()\n",
    "s_dim = env.state_dim\n",
    "a_dim = env.action_dim\n",
    "a_bound = env.action_bound\n",
    "\n",
    "# set RL method (continuous)\n",
    "rl = DDPG(a_dim, s_dim, a_bound)\n",
    "\n",
    "steps = []\n",
    "def train():\n",
    "    # start training\n",
    "    for i in range(MAX_EPISODES):\n",
    "        s = env.reset()\n",
    "        ep_r = 0.\n",
    "        for j in range(MAX_EP_STEPS):\n",
    "            # env.render()\n",
    "\n",
    "            a = rl.choose_action(s)\n",
    "\n",
    "            s_, r, done = env.step(a)\n",
    "\n",
    "            rl.store_transition(s, a, r, s_)\n",
    "\n",
    "            ep_r += r\n",
    "            if rl.memory_full:\n",
    "                # start to learn once has fulfilled the memory\n",
    "                rl.learn()\n",
    "\n",
    "            s = s_\n",
    "            if done or j == MAX_EP_STEPS-1:\n",
    "                print('Ep: %i | %s | ep_r: %.1f | step: %i' % (i, '---' if not done else 'done', ep_r, j))\n",
    "                break\n",
    "    rl.save()\n",
    "\n",
    "\n",
    "def eval_model():\n",
    "    rl.restore()\n",
    "    env.render()\n",
    "    env.viewer.set_vsync(True)\n",
    "    s = env.reset()\n",
    "    while True:\n",
    "        env.render()\n",
    "        a = rl.choose_action(s)\n",
    "        s, r, done = env.step(a)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep: 0 | --- | ep_r: -137.7 | step: 349\n",
      "Ep: 1 | --- | ep_r: -113.0 | step: 349\n",
      "Ep: 2 | --- | ep_r: -90.9 | step: 349\n",
      "Ep: 3 | --- | ep_r: -91.6 | step: 349\n",
      "Ep: 4 | --- | ep_r: -172.1 | step: 349\n",
      "Ep: 5 | --- | ep_r: -196.6 | step: 349\n",
      "Ep: 6 | --- | ep_r: -218.1 | step: 349\n",
      "Ep: 7 | --- | ep_r: -166.7 | step: 349\n",
      "Ep: 8 | done | ep_r: 40.5 | step: 172\n",
      "Ep: 9 | --- | ep_r: -74.0 | step: 349\n",
      "Ep: 10 | done | ep_r: 13.4 | step: 220\n",
      "Ep: 11 | --- | ep_r: -346.9 | step: 349\n",
      "Ep: 12 | --- | ep_r: -155.2 | step: 349\n",
      "Ep: 13 | --- | ep_r: -204.8 | step: 349\n",
      "Ep: 14 | --- | ep_r: -147.5 | step: 349\n",
      "Ep: 15 | --- | ep_r: -87.0 | step: 349\n",
      "Ep: 16 | --- | ep_r: -175.5 | step: 349\n",
      "Ep: 17 | --- | ep_r: -101.7 | step: 349\n",
      "Ep: 18 | --- | ep_r: -176.6 | step: 349\n",
      "Ep: 19 | --- | ep_r: -158.3 | step: 349\n",
      "Ep: 20 | --- | ep_r: -161.9 | step: 349\n",
      "Ep: 21 | --- | ep_r: -253.5 | step: 349\n",
      "Ep: 22 | --- | ep_r: -189.8 | step: 349\n",
      "Ep: 23 | --- | ep_r: -248.7 | step: 349\n",
      "Ep: 24 | --- | ep_r: -135.4 | step: 349\n",
      "Ep: 25 | --- | ep_r: -200.2 | step: 349\n",
      "Ep: 26 | --- | ep_r: -212.5 | step: 349\n",
      "Ep: 27 | --- | ep_r: -242.5 | step: 349\n",
      "Ep: 28 | --- | ep_r: -199.8 | step: 349\n",
      "Ep: 29 | --- | ep_r: -130.4 | step: 349\n",
      "Ep: 30 | --- | ep_r: -213.3 | step: 349\n",
      "Ep: 31 | --- | ep_r: -111.5 | step: 349\n",
      "Ep: 32 | --- | ep_r: -128.8 | step: 349\n",
      "Ep: 33 | --- | ep_r: -110.0 | step: 349\n",
      "Ep: 34 | --- | ep_r: -150.2 | step: 349\n",
      "Ep: 35 | --- | ep_r: -233.1 | step: 349\n",
      "Ep: 36 | --- | ep_r: -84.6 | step: 349\n",
      "Ep: 37 | --- | ep_r: -292.6 | step: 349\n",
      "Ep: 38 | --- | ep_r: -79.4 | step: 349\n",
      "Ep: 39 | --- | ep_r: -62.5 | step: 349\n",
      "Ep: 40 | --- | ep_r: -217.7 | step: 349\n",
      "Ep: 41 | --- | ep_r: -223.1 | step: 349\n",
      "Ep: 42 | --- | ep_r: -256.0 | step: 349\n",
      "Ep: 43 | --- | ep_r: -172.9 | step: 349\n",
      "Ep: 44 | --- | ep_r: -144.4 | step: 349\n",
      "Ep: 45 | --- | ep_r: -146.9 | step: 349\n",
      "Ep: 46 | --- | ep_r: -119.5 | step: 349\n",
      "Ep: 47 | --- | ep_r: -312.9 | step: 349\n",
      "Ep: 48 | --- | ep_r: -165.1 | step: 349\n",
      "Ep: 49 | --- | ep_r: -183.2 | step: 349\n",
      "Ep: 50 | --- | ep_r: -202.8 | step: 349\n",
      "Ep: 51 | --- | ep_r: -293.1 | step: 349\n",
      "Ep: 52 | done | ep_r: -38.0 | step: 294\n",
      "Ep: 53 | --- | ep_r: -172.2 | step: 349\n",
      "Ep: 54 | --- | ep_r: -261.9 | step: 349\n",
      "Ep: 55 | --- | ep_r: -342.3 | step: 349\n",
      "Ep: 56 | --- | ep_r: -146.4 | step: 349\n",
      "Ep: 57 | --- | ep_r: -106.1 | step: 349\n",
      "Ep: 58 | --- | ep_r: -144.3 | step: 349\n",
      "Ep: 59 | --- | ep_r: -184.0 | step: 349\n",
      "Ep: 60 | --- | ep_r: -112.6 | step: 349\n",
      "Ep: 61 | --- | ep_r: -124.0 | step: 349\n",
      "Ep: 62 | --- | ep_r: -66.0 | step: 349\n",
      "Ep: 63 | --- | ep_r: -97.8 | step: 349\n",
      "Ep: 64 | --- | ep_r: -202.2 | step: 349\n",
      "Ep: 65 | --- | ep_r: -148.9 | step: 349\n",
      "Ep: 66 | --- | ep_r: -217.0 | step: 349\n",
      "Ep: 67 | --- | ep_r: -86.4 | step: 349\n",
      "Ep: 68 | --- | ep_r: -88.9 | step: 349\n",
      "Ep: 69 | --- | ep_r: -136.1 | step: 349\n",
      "Ep: 70 | --- | ep_r: -239.4 | step: 349\n",
      "Ep: 71 | --- | ep_r: -205.1 | step: 349\n",
      "Ep: 72 | --- | ep_r: -339.0 | step: 349\n",
      "Ep: 73 | --- | ep_r: -164.4 | step: 349\n",
      "Ep: 74 | --- | ep_r: -83.4 | step: 349\n",
      "Ep: 75 | --- | ep_r: -184.6 | step: 349\n",
      "Ep: 76 | done | ep_r: 20.3 | step: 203\n",
      "Ep: 77 | --- | ep_r: -293.7 | step: 349\n",
      "Ep: 78 | --- | ep_r: -287.0 | step: 349\n",
      "Ep: 79 | done | ep_r: 44.7 | step: 95\n",
      "Ep: 80 | --- | ep_r: -134.2 | step: 349\n",
      "Ep: 81 | --- | ep_r: -241.5 | step: 349\n",
      "Ep: 82 | --- | ep_r: -216.5 | step: 349\n",
      "Ep: 83 | --- | ep_r: -177.9 | step: 349\n",
      "Ep: 84 | --- | ep_r: -148.7 | step: 349\n",
      "Ep: 85 | --- | ep_r: -292.5 | step: 349\n",
      "Ep: 86 | --- | ep_r: -165.5 | step: 349\n",
      "Ep: 87 | --- | ep_r: -187.3 | step: 349\n",
      "Ep: 88 | --- | ep_r: -207.7 | step: 349\n",
      "Ep: 89 | --- | ep_r: -204.1 | step: 349\n",
      "Ep: 90 | --- | ep_r: -201.1 | step: 349\n",
      "Ep: 91 | --- | ep_r: -122.7 | step: 349\n",
      "Ep: 92 | --- | ep_r: -139.3 | step: 349\n",
      "Ep: 93 | --- | ep_r: -60.9 | step: 349\n",
      "Ep: 94 | --- | ep_r: -269.6 | step: 349\n",
      "Ep: 95 | --- | ep_r: -133.2 | step: 349\n",
      "Ep: 96 | --- | ep_r: -106.7 | step: 349\n",
      "Ep: 97 | --- | ep_r: -100.4 | step: 349\n",
      "Ep: 98 | --- | ep_r: -173.1 | step: 349\n",
      "Ep: 99 | --- | ep_r: -180.2 | step: 349\n",
      "Ep: 100 | --- | ep_r: -166.4 | step: 349\n",
      "Ep: 101 | --- | ep_r: -115.1 | step: 349\n",
      "Ep: 102 | --- | ep_r: -12.5 | step: 349\n",
      "Ep: 103 | --- | ep_r: -204.0 | step: 349\n",
      "Ep: 104 | --- | ep_r: -32.7 | step: 349\n",
      "Ep: 105 | --- | ep_r: -93.3 | step: 349\n",
      "Ep: 106 | --- | ep_r: -153.7 | step: 349\n",
      "Ep: 107 | --- | ep_r: -82.6 | step: 349\n",
      "Ep: 108 | --- | ep_r: 17.8 | step: 349\n",
      "Ep: 109 | --- | ep_r: -98.2 | step: 349\n",
      "Ep: 110 | --- | ep_r: -206.5 | step: 349\n",
      "Ep: 111 | --- | ep_r: -136.8 | step: 349\n",
      "Ep: 112 | --- | ep_r: -92.3 | step: 349\n",
      "Ep: 113 | --- | ep_r: -125.9 | step: 349\n",
      "Ep: 114 | --- | ep_r: -112.9 | step: 349\n",
      "Ep: 115 | --- | ep_r: -54.0 | step: 349\n",
      "Ep: 116 | --- | ep_r: -143.3 | step: 349\n",
      "Ep: 117 | --- | ep_r: -207.3 | step: 349\n",
      "Ep: 118 | --- | ep_r: -79.1 | step: 349\n",
      "Ep: 119 | --- | ep_r: -114.1 | step: 349\n",
      "Ep: 120 | --- | ep_r: -51.5 | step: 349\n",
      "Ep: 121 | --- | ep_r: -102.3 | step: 349\n",
      "Ep: 122 | --- | ep_r: -129.5 | step: 349\n",
      "Ep: 123 | --- | ep_r: -53.9 | step: 349\n",
      "Ep: 124 | --- | ep_r: -79.7 | step: 349\n",
      "Ep: 125 | --- | ep_r: -152.4 | step: 349\n",
      "Ep: 126 | --- | ep_r: -131.9 | step: 349\n",
      "Ep: 127 | --- | ep_r: -85.7 | step: 349\n",
      "Ep: 128 | --- | ep_r: -143.3 | step: 349\n",
      "Ep: 129 | --- | ep_r: -138.9 | step: 349\n",
      "Ep: 130 | --- | ep_r: -90.9 | step: 349\n",
      "Ep: 131 | --- | ep_r: -195.8 | step: 349\n",
      "Ep: 132 | --- | ep_r: -12.5 | step: 349\n",
      "Ep: 133 | --- | ep_r: 47.0 | step: 349\n",
      "Ep: 134 | --- | ep_r: -73.2 | step: 349\n",
      "Ep: 135 | --- | ep_r: -74.0 | step: 349\n",
      "Ep: 136 | --- | ep_r: -31.0 | step: 349\n",
      "Ep: 137 | --- | ep_r: -114.7 | step: 349\n",
      "Ep: 138 | --- | ep_r: -21.4 | step: 349\n",
      "Ep: 139 | done | ep_r: 95.8 | step: 260\n",
      "Ep: 140 | --- | ep_r: -63.1 | step: 349\n",
      "Ep: 141 | --- | ep_r: -45.1 | step: 349\n",
      "Ep: 142 | --- | ep_r: -90.4 | step: 349\n",
      "Ep: 143 | --- | ep_r: -40.6 | step: 349\n",
      "Ep: 144 | --- | ep_r: -17.7 | step: 349\n",
      "Ep: 145 | --- | ep_r: -37.2 | step: 349\n",
      "Ep: 146 | --- | ep_r: -64.1 | step: 349\n",
      "Ep: 147 | --- | ep_r: -103.0 | step: 349\n",
      "Ep: 148 | --- | ep_r: -76.4 | step: 349\n",
      "Ep: 149 | --- | ep_r: -147.9 | step: 349\n",
      "Ep: 150 | --- | ep_r: -64.5 | step: 349\n",
      "Ep: 151 | done | ep_r: 18.8 | step: 311\n",
      "Ep: 152 | --- | ep_r: -56.8 | step: 349\n",
      "Ep: 153 | --- | ep_r: -137.1 | step: 349\n",
      "Ep: 154 | --- | ep_r: -45.7 | step: 349\n",
      "Ep: 155 | --- | ep_r: -115.7 | step: 349\n",
      "Ep: 156 | --- | ep_r: -23.1 | step: 349\n",
      "Ep: 157 | --- | ep_r: -76.4 | step: 349\n",
      "Ep: 158 | --- | ep_r: -14.6 | step: 349\n",
      "Ep: 159 | --- | ep_r: -67.6 | step: 349\n",
      "Ep: 160 | --- | ep_r: -86.5 | step: 349\n",
      "Ep: 161 | --- | ep_r: -92.2 | step: 349\n",
      "Ep: 162 | --- | ep_r: -25.4 | step: 349\n",
      "Ep: 163 | --- | ep_r: 161.0 | step: 349\n",
      "Ep: 164 | --- | ep_r: -102.7 | step: 349\n",
      "Ep: 165 | --- | ep_r: -102.1 | step: 349\n",
      "Ep: 166 | --- | ep_r: -50.2 | step: 349\n",
      "Ep: 167 | --- | ep_r: -91.7 | step: 349\n",
      "Ep: 168 | --- | ep_r: -8.2 | step: 349\n",
      "Ep: 169 | --- | ep_r: -86.3 | step: 349\n",
      "Ep: 170 | --- | ep_r: 241.1 | step: 349\n",
      "Ep: 171 | --- | ep_r: -115.0 | step: 349\n",
      "Ep: 172 | --- | ep_r: -60.3 | step: 349\n",
      "Ep: 173 | --- | ep_r: -25.3 | step: 349\n",
      "Ep: 174 | --- | ep_r: -22.8 | step: 349\n",
      "Ep: 175 | --- | ep_r: -72.7 | step: 349\n",
      "Ep: 176 | --- | ep_r: 269.7 | step: 349\n",
      "Ep: 177 | --- | ep_r: -89.2 | step: 349\n",
      "Ep: 178 | --- | ep_r: -31.1 | step: 349\n",
      "Ep: 179 | --- | ep_r: -68.1 | step: 349\n",
      "Ep: 180 | --- | ep_r: 7.5 | step: 349\n",
      "Ep: 181 | --- | ep_r: 47.4 | step: 349\n",
      "Ep: 182 | --- | ep_r: -7.7 | step: 349\n",
      "Ep: 183 | --- | ep_r: -91.3 | step: 349\n",
      "Ep: 184 | --- | ep_r: 47.4 | step: 349\n",
      "Ep: 185 | --- | ep_r: -94.1 | step: 349\n",
      "Ep: 186 | --- | ep_r: -41.1 | step: 349\n",
      "Ep: 187 | --- | ep_r: -16.6 | step: 349\n",
      "Ep: 188 | --- | ep_r: 204.6 | step: 349\n",
      "Ep: 189 | --- | ep_r: 171.5 | step: 349\n",
      "Ep: 190 | done | ep_r: 47.5 | step: 68\n",
      "Ep: 191 | --- | ep_r: -49.7 | step: 349\n",
      "Ep: 192 | --- | ep_r: -26.7 | step: 349\n",
      "Ep: 193 | --- | ep_r: -72.7 | step: 349\n",
      "Ep: 194 | done | ep_r: 49.4 | step: 50\n",
      "Ep: 195 | --- | ep_r: -46.4 | step: 349\n",
      "Ep: 196 | --- | ep_r: -56.1 | step: 349\n",
      "Ep: 197 | --- | ep_r: -63.6 | step: 349\n",
      "Ep: 198 | done | ep_r: 221.0 | step: 260\n",
      "Ep: 199 | --- | ep_r: -64.6 | step: 349\n",
      "Ep: 200 | --- | ep_r: -59.8 | step: 349\n",
      "Ep: 201 | --- | ep_r: 58.7 | step: 349\n",
      "Ep: 202 | --- | ep_r: -141.6 | step: 349\n",
      "Ep: 203 | --- | ep_r: -43.7 | step: 349\n",
      "Ep: 204 | --- | ep_r: -72.0 | step: 349\n",
      "Ep: 205 | --- | ep_r: -95.0 | step: 349\n",
      "Ep: 206 | --- | ep_r: -86.3 | step: 349\n",
      "Ep: 207 | --- | ep_r: 152.8 | step: 349\n",
      "Ep: 208 | --- | ep_r: -81.5 | step: 349\n",
      "Ep: 209 | --- | ep_r: -64.7 | step: 349\n",
      "Ep: 210 | --- | ep_r: 176.7 | step: 349\n",
      "Ep: 211 | --- | ep_r: -20.4 | step: 349\n",
      "Ep: 212 | --- | ep_r: -9.1 | step: 349\n",
      "Ep: 213 | --- | ep_r: 184.7 | step: 349\n",
      "Ep: 214 | done | ep_r: 185.8 | step: 346\n",
      "Ep: 215 | --- | ep_r: -27.3 | step: 349\n",
      "Ep: 216 | --- | ep_r: -44.0 | step: 349\n",
      "Ep: 217 | --- | ep_r: -74.6 | step: 349\n",
      "Ep: 218 | --- | ep_r: -129.1 | step: 349\n",
      "Ep: 219 | --- | ep_r: -35.4 | step: 349\n",
      "Ep: 220 | --- | ep_r: -36.0 | step: 349\n",
      "Ep: 221 | --- | ep_r: -26.4 | step: 349\n",
      "Ep: 222 | --- | ep_r: -49.7 | step: 349\n",
      "Ep: 223 | --- | ep_r: 164.6 | step: 349\n",
      "Ep: 224 | --- | ep_r: -96.1 | step: 349\n",
      "Ep: 225 | done | ep_r: 45.9 | step: 65\n",
      "Ep: 226 | done | ep_r: 52.6 | step: 57\n",
      "Ep: 227 | --- | ep_r: 178.5 | step: 349\n",
      "Ep: 228 | --- | ep_r: -83.8 | step: 349\n",
      "Ep: 229 | done | ep_r: 41.6 | step: 80\n",
      "Ep: 230 | --- | ep_r: -112.4 | step: 349\n",
      "Ep: 231 | --- | ep_r: -39.6 | step: 349\n",
      "Ep: 232 | --- | ep_r: -58.1 | step: 349\n",
      "Ep: 233 | done | ep_r: 37.9 | step: 85\n",
      "Ep: 234 | --- | ep_r: -30.5 | step: 349\n",
      "Ep: 235 | --- | ep_r: 158.4 | step: 349\n",
      "Ep: 236 | --- | ep_r: -52.9 | step: 349\n",
      "Ep: 237 | --- | ep_r: -52.8 | step: 349\n",
      "Ep: 238 | done | ep_r: 49.1 | step: 60\n",
      "Ep: 239 | --- | ep_r: -78.2 | step: 349\n",
      "Ep: 240 | --- | ep_r: -91.0 | step: 349\n",
      "Ep: 241 | --- | ep_r: -73.4 | step: 349\n",
      "Ep: 242 | --- | ep_r: -39.9 | step: 349\n",
      "Ep: 243 | done | ep_r: 43.5 | step: 71\n",
      "Ep: 244 | --- | ep_r: 266.4 | step: 349\n",
      "Ep: 245 | done | ep_r: 223.3 | step: 290\n",
      "Ep: 246 | --- | ep_r: -49.1 | step: 349\n",
      "Ep: 247 | --- | ep_r: -85.3 | step: 349\n",
      "Ep: 248 | --- | ep_r: -80.6 | step: 349\n",
      "Ep: 249 | --- | ep_r: -60.6 | step: 349\n",
      "Ep: 250 | --- | ep_r: 120.0 | step: 349\n",
      "Ep: 251 | done | ep_r: 121.8 | step: 171\n",
      "Ep: 252 | --- | ep_r: -150.4 | step: 349\n",
      "Ep: 253 | --- | ep_r: 17.2 | step: 349\n",
      "Ep: 254 | --- | ep_r: -50.9 | step: 349\n",
      "Ep: 255 | done | ep_r: 17.6 | step: 127\n",
      "Ep: 256 | --- | ep_r: -113.0 | step: 349\n",
      "Ep: 257 | --- | ep_r: -101.9 | step: 349\n",
      "Ep: 258 | --- | ep_r: -69.8 | step: 349\n",
      "Ep: 259 | done | ep_r: 44.3 | step: 69\n",
      "Ep: 260 | --- | ep_r: 298.0 | step: 349\n",
      "Ep: 261 | done | ep_r: 34.3 | step: 97\n",
      "Ep: 262 | --- | ep_r: 105.1 | step: 349\n",
      "Ep: 263 | --- | ep_r: -53.0 | step: 349\n",
      "Ep: 264 | --- | ep_r: -62.3 | step: 349\n",
      "Ep: 265 | --- | ep_r: 272.3 | step: 349\n",
      "Ep: 266 | --- | ep_r: -134.5 | step: 349\n",
      "Ep: 267 | done | ep_r: 47.3 | step: 65\n",
      "Ep: 268 | --- | ep_r: 197.0 | step: 349\n",
      "Ep: 269 | --- | ep_r: -143.6 | step: 349\n",
      "Ep: 270 | --- | ep_r: -69.9 | step: 349\n",
      "Ep: 271 | --- | ep_r: -72.0 | step: 349\n",
      "Ep: 272 | --- | ep_r: -39.5 | step: 349\n",
      "Ep: 273 | done | ep_r: 24.5 | step: 280\n",
      "Ep: 274 | --- | ep_r: -58.9 | step: 349\n",
      "Ep: 275 | done | ep_r: 49.4 | step: 53\n",
      "Ep: 276 | --- | ep_r: -95.2 | step: 349\n",
      "Ep: 277 | --- | ep_r: -50.2 | step: 349\n",
      "Ep: 278 | --- | ep_r: -63.3 | step: 349\n",
      "Ep: 279 | --- | ep_r: -73.4 | step: 349\n",
      "Ep: 280 | done | ep_r: 40.8 | step: 113\n",
      "Ep: 281 | --- | ep_r: -38.3 | step: 349\n",
      "Ep: 282 | --- | ep_r: -30.0 | step: 349\n",
      "Ep: 283 | --- | ep_r: -91.4 | step: 349\n",
      "Ep: 284 | done | ep_r: 43.8 | step: 70\n",
      "Ep: 285 | --- | ep_r: 10.8 | step: 349\n",
      "Ep: 286 | done | ep_r: 49.6 | step: 52\n",
      "Ep: 287 | --- | ep_r: -46.9 | step: 349\n",
      "Ep: 288 | --- | ep_r: -106.6 | step: 349\n",
      "Ep: 289 | --- | ep_r: -51.2 | step: 349\n",
      "Ep: 290 | --- | ep_r: -56.0 | step: 349\n",
      "Ep: 291 | --- | ep_r: -92.9 | step: 349\n",
      "Ep: 292 | done | ep_r: 47.9 | step: 62\n",
      "Ep: 293 | --- | ep_r: -66.2 | step: 349\n",
      "Ep: 294 | --- | ep_r: -31.7 | step: 349\n",
      "Ep: 295 | --- | ep_r: -44.8 | step: 349\n",
      "Ep: 296 | --- | ep_r: 62.5 | step: 349\n",
      "Ep: 297 | --- | ep_r: 178.6 | step: 349\n",
      "Ep: 298 | --- | ep_r: 156.9 | step: 349\n",
      "Ep: 299 | --- | ep_r: -55.9 | step: 349\n",
      "Ep: 300 | done | ep_r: 99.7 | step: 214\n",
      "Ep: 301 | --- | ep_r: -36.8 | step: 349\n",
      "Ep: 302 | --- | ep_r: 55.6 | step: 349\n",
      "Ep: 303 | --- | ep_r: 124.1 | step: 349\n",
      "Ep: 304 | --- | ep_r: -94.7 | step: 349\n",
      "Ep: 305 | --- | ep_r: -99.8 | step: 349\n",
      "Ep: 306 | --- | ep_r: -78.9 | step: 349\n",
      "Ep: 307 | done | ep_r: 31.0 | step: 106\n",
      "Ep: 308 | --- | ep_r: -30.4 | step: 349\n",
      "Ep: 309 | --- | ep_r: -35.5 | step: 349\n",
      "Ep: 310 | --- | ep_r: 0.6 | step: 349\n",
      "Ep: 311 | done | ep_r: 48.4 | step: 65\n",
      "Ep: 312 | --- | ep_r: 248.6 | step: 349\n",
      "Ep: 313 | --- | ep_r: -58.7 | step: 349\n",
      "Ep: 314 | done | ep_r: 45.5 | step: 66\n",
      "Ep: 315 | --- | ep_r: -69.3 | step: 349\n",
      "Ep: 316 | --- | ep_r: -60.0 | step: 349\n",
      "Ep: 317 | --- | ep_r: 7.6 | step: 349\n",
      "Ep: 318 | --- | ep_r: 239.6 | step: 349\n",
      "Ep: 319 | --- | ep_r: 253.0 | step: 349\n",
      "Ep: 320 | --- | ep_r: -79.4 | step: 349\n",
      "Ep: 321 | --- | ep_r: 288.4 | step: 349\n",
      "Ep: 322 | done | ep_r: 36.9 | step: 137\n",
      "Ep: 323 | --- | ep_r: -87.1 | step: 349\n",
      "Ep: 324 | --- | ep_r: -61.5 | step: 349\n",
      "Ep: 325 | done | ep_r: 34.3 | step: 150\n",
      "Ep: 326 | --- | ep_r: -107.6 | step: 349\n",
      "Ep: 327 | done | ep_r: 43.7 | step: 77\n",
      "Ep: 328 | --- | ep_r: -57.6 | step: 349\n",
      "Ep: 329 | --- | ep_r: -89.9 | step: 349\n",
      "Ep: 330 | done | ep_r: 46.9 | step: 63\n",
      "Ep: 331 | done | ep_r: 45.2 | step: 74\n",
      "Ep: 332 | done | ep_r: 165.6 | step: 252\n",
      "Ep: 333 | done | ep_r: 273.9 | step: 323\n",
      "Ep: 334 | --- | ep_r: -120.6 | step: 349\n",
      "Ep: 335 | --- | ep_r: -66.8 | step: 349\n",
      "Ep: 336 | --- | ep_r: -108.2 | step: 349\n",
      "Ep: 337 | --- | ep_r: -54.2 | step: 349\n",
      "Ep: 338 | --- | ep_r: -17.5 | step: 349\n",
      "Ep: 339 | --- | ep_r: 250.0 | step: 349\n",
      "Ep: 340 | --- | ep_r: -98.6 | step: 349\n",
      "Ep: 341 | done | ep_r: 72.8 | step: 278\n",
      "Ep: 342 | done | ep_r: 42.0 | step: 65\n",
      "Ep: 343 | done | ep_r: 82.0 | step: 303\n",
      "Ep: 344 | --- | ep_r: 163.2 | step: 349\n",
      "Ep: 345 | --- | ep_r: -74.4 | step: 349\n",
      "Ep: 346 | --- | ep_r: 14.7 | step: 349\n",
      "Ep: 347 | done | ep_r: 46.8 | step: 66\n",
      "Ep: 348 | done | ep_r: 43.6 | step: 81\n",
      "Ep: 349 | --- | ep_r: 194.5 | step: 349\n",
      "Ep: 350 | done | ep_r: 70.9 | step: 98\n",
      "Ep: 351 | --- | ep_r: -61.4 | step: 349\n",
      "Ep: 352 | --- | ep_r: -37.0 | step: 349\n",
      "Ep: 353 | --- | ep_r: -71.7 | step: 349\n",
      "Ep: 354 | --- | ep_r: -52.6 | step: 349\n",
      "Ep: 355 | --- | ep_r: -61.3 | step: 349\n",
      "Ep: 356 | done | ep_r: 46.8 | step: 58\n",
      "Ep: 357 | done | ep_r: 48.3 | step: 56\n",
      "Ep: 358 | --- | ep_r: 11.8 | step: 349\n",
      "Ep: 359 | done | ep_r: 52.3 | step: 233\n",
      "Ep: 360 | --- | ep_r: -72.3 | step: 349\n",
      "Ep: 361 | --- | ep_r: -38.9 | step: 349\n",
      "Ep: 362 | done | ep_r: 44.9 | step: 190\n",
      "Ep: 363 | --- | ep_r: -79.6 | step: 349\n",
      "Ep: 364 | done | ep_r: 50.5 | step: 135\n",
      "Ep: 365 | --- | ep_r: -42.3 | step: 349\n",
      "Ep: 366 | done | ep_r: 148.2 | step: 173\n",
      "Ep: 367 | --- | ep_r: -60.6 | step: 349\n",
      "Ep: 368 | --- | ep_r: 24.1 | step: 349\n",
      "Ep: 369 | --- | ep_r: -48.0 | step: 349\n",
      "Ep: 370 | --- | ep_r: 202.7 | step: 349\n",
      "Ep: 371 | --- | ep_r: -61.0 | step: 349\n",
      "Ep: 372 | --- | ep_r: -78.0 | step: 349\n",
      "Ep: 373 | --- | ep_r: 286.7 | step: 349\n",
      "Ep: 374 | --- | ep_r: -55.1 | step: 349\n",
      "Ep: 375 | --- | ep_r: 256.3 | step: 349\n",
      "Ep: 376 | --- | ep_r: -119.1 | step: 349\n",
      "Ep: 377 | done | ep_r: 104.7 | step: 143\n",
      "Ep: 378 | --- | ep_r: -48.1 | step: 349\n",
      "Ep: 379 | done | ep_r: 48.1 | step: 75\n",
      "Ep: 380 | --- | ep_r: 291.6 | step: 349\n",
      "Ep: 381 | --- | ep_r: -24.8 | step: 349\n",
      "Ep: 382 | --- | ep_r: -45.2 | step: 349\n",
      "Ep: 383 | --- | ep_r: -182.6 | step: 349\n",
      "Ep: 384 | --- | ep_r: -51.5 | step: 349\n",
      "Ep: 385 | done | ep_r: 46.2 | step: 65\n",
      "Ep: 386 | --- | ep_r: -103.4 | step: 349\n",
      "Ep: 387 | done | ep_r: 75.6 | step: 88\n",
      "Ep: 388 | done | ep_r: 39.8 | step: 172\n",
      "Ep: 389 | done | ep_r: 208.6 | step: 317\n",
      "Ep: 390 | done | ep_r: 27.9 | step: 231\n",
      "Ep: 391 | --- | ep_r: -51.4 | step: 349\n",
      "Ep: 392 | --- | ep_r: -58.1 | step: 349\n",
      "Ep: 393 | --- | ep_r: -51.9 | step: 349\n",
      "Ep: 394 | done | ep_r: 35.9 | step: 75\n",
      "Ep: 395 | done | ep_r: 42.5 | step: 98\n",
      "Ep: 396 | done | ep_r: 122.8 | step: 245\n",
      "Ep: 397 | --- | ep_r: -48.8 | step: 349\n",
      "Ep: 398 | done | ep_r: 114.6 | step: 206\n",
      "Ep: 399 | done | ep_r: 43.2 | step: 78\n",
      "Ep: 400 | --- | ep_r: -48.0 | step: 349\n",
      "Ep: 401 | --- | ep_r: -72.8 | step: 349\n",
      "Ep: 402 | done | ep_r: 261.6 | step: 303\n",
      "Ep: 403 | --- | ep_r: -26.1 | step: 349\n",
      "Ep: 404 | done | ep_r: 20.5 | step: 122\n",
      "Ep: 405 | --- | ep_r: -6.7 | step: 349\n",
      "Ep: 406 | done | ep_r: 26.7 | step: 289\n",
      "Ep: 407 | --- | ep_r: 207.9 | step: 349\n",
      "Ep: 408 | --- | ep_r: -52.9 | step: 349\n",
      "Ep: 409 | --- | ep_r: 130.1 | step: 349\n",
      "Ep: 410 | done | ep_r: 39.5 | step: 67\n",
      "Ep: 411 | --- | ep_r: -47.4 | step: 349\n",
      "Ep: 412 | --- | ep_r: -56.0 | step: 349\n",
      "Ep: 413 | --- | ep_r: -42.5 | step: 349\n",
      "Ep: 414 | --- | ep_r: 154.7 | step: 349\n",
      "Ep: 415 | done | ep_r: 187.4 | step: 318\n",
      "Ep: 416 | --- | ep_r: 150.8 | step: 349\n",
      "Ep: 417 | --- | ep_r: -57.8 | step: 349\n",
      "Ep: 418 | --- | ep_r: -37.4 | step: 349\n",
      "Ep: 419 | done | ep_r: 61.6 | step: 133\n",
      "Ep: 420 | --- | ep_r: 67.9 | step: 349\n",
      "Ep: 421 | --- | ep_r: -45.1 | step: 349\n",
      "Ep: 422 | done | ep_r: 39.7 | step: 85\n",
      "Ep: 423 | done | ep_r: 46.4 | step: 59\n",
      "Ep: 424 | --- | ep_r: -17.1 | step: 349\n",
      "Ep: 425 | --- | ep_r: -10.8 | step: 349\n",
      "Ep: 426 | --- | ep_r: 241.4 | step: 349\n",
      "Ep: 427 | --- | ep_r: 67.9 | step: 349\n",
      "Ep: 428 | done | ep_r: 32.0 | step: 96\n",
      "Ep: 429 | --- | ep_r: 219.9 | step: 349\n",
      "Ep: 430 | --- | ep_r: -54.0 | step: 349\n",
      "Ep: 431 | done | ep_r: 49.2 | step: 50\n",
      "Ep: 432 | --- | ep_r: -58.2 | step: 349\n",
      "Ep: 433 | done | ep_r: 47.5 | step: 60\n",
      "Ep: 434 | --- | ep_r: -51.6 | step: 349\n",
      "Ep: 435 | --- | ep_r: 50.4 | step: 349\n",
      "Ep: 436 | --- | ep_r: -38.0 | step: 349\n",
      "Ep: 437 | --- | ep_r: 221.6 | step: 349\n",
      "Ep: 438 | --- | ep_r: -53.6 | step: 349\n",
      "Ep: 439 | --- | ep_r: -34.0 | step: 349\n",
      "Ep: 440 | done | ep_r: 25.8 | step: 113\n",
      "Ep: 441 | done | ep_r: 36.4 | step: 91\n",
      "Ep: 442 | --- | ep_r: -49.1 | step: 349\n",
      "Ep: 443 | --- | ep_r: -24.1 | step: 349\n",
      "Ep: 444 | done | ep_r: 263.4 | step: 312\n",
      "Ep: 445 | --- | ep_r: -42.6 | step: 349\n",
      "Ep: 446 | done | ep_r: 77.3 | step: 232\n",
      "Ep: 447 | done | ep_r: 39.0 | step: 138\n",
      "Ep: 448 | --- | ep_r: -39.6 | step: 349\n",
      "Ep: 449 | done | ep_r: 45.6 | step: 82\n",
      "Ep: 450 | --- | ep_r: -52.4 | step: 349\n",
      "Ep: 451 | --- | ep_r: -151.1 | step: 349\n",
      "Ep: 452 | --- | ep_r: -67.7 | step: 349\n",
      "Ep: 453 | --- | ep_r: 179.7 | step: 349\n",
      "Ep: 454 | --- | ep_r: -3.1 | step: 349\n",
      "Ep: 455 | done | ep_r: 44.6 | step: 66\n",
      "Ep: 456 | --- | ep_r: -53.1 | step: 349\n",
      "Ep: 457 | --- | ep_r: -17.4 | step: 349\n",
      "Ep: 458 | --- | ep_r: 12.2 | step: 349\n",
      "Ep: 459 | --- | ep_r: -34.9 | step: 349\n",
      "Ep: 460 | --- | ep_r: -162.1 | step: 349\n",
      "Ep: 461 | --- | ep_r: -28.7 | step: 349\n",
      "Ep: 462 | done | ep_r: 43.7 | step: 70\n",
      "Ep: 463 | --- | ep_r: -52.3 | step: 349\n",
      "Ep: 464 | --- | ep_r: 209.7 | step: 349\n",
      "Ep: 465 | done | ep_r: 63.8 | step: 89\n",
      "Ep: 466 | done | ep_r: 67.2 | step: 144\n",
      "Ep: 467 | done | ep_r: 45.5 | step: 66\n",
      "Ep: 468 | done | ep_r: 46.5 | step: 61\n",
      "Ep: 469 | done | ep_r: 154.7 | step: 217\n",
      "Ep: 470 | --- | ep_r: -48.1 | step: 349\n",
      "Ep: 471 | --- | ep_r: -100.3 | step: 349\n",
      "Ep: 472 | done | ep_r: 74.7 | step: 125\n",
      "Ep: 473 | --- | ep_r: -60.7 | step: 349\n",
      "Ep: 474 | done | ep_r: 8.1 | step: 292\n",
      "Ep: 475 | --- | ep_r: 156.5 | step: 349\n",
      "Ep: 476 | --- | ep_r: 122.4 | step: 349\n",
      "Ep: 477 | --- | ep_r: -26.0 | step: 349\n",
      "Ep: 478 | --- | ep_r: 235.1 | step: 349\n",
      "Ep: 479 | --- | ep_r: 157.1 | step: 349\n",
      "Ep: 480 | --- | ep_r: 13.7 | step: 349\n",
      "Ep: 481 | --- | ep_r: 164.9 | step: 349\n",
      "Ep: 482 | --- | ep_r: 215.1 | step: 349\n",
      "Ep: 483 | done | ep_r: 31.3 | step: 230\n",
      "Ep: 484 | --- | ep_r: 147.4 | step: 349\n",
      "Ep: 485 | done | ep_r: 44.6 | step: 88\n",
      "Ep: 486 | --- | ep_r: -49.8 | step: 349\n",
      "Ep: 487 | --- | ep_r: -73.1 | step: 349\n",
      "Ep: 488 | --- | ep_r: 55.1 | step: 349\n",
      "Ep: 489 | done | ep_r: 32.0 | step: 99\n",
      "Ep: 490 | --- | ep_r: -9.1 | step: 349\n",
      "Ep: 491 | --- | ep_r: 107.2 | step: 349\n",
      "Ep: 492 | --- | ep_r: -50.8 | step: 349\n",
      "Ep: 493 | --- | ep_r: 15.5 | step: 349\n",
      "Ep: 494 | --- | ep_r: 15.9 | step: 349\n",
      "Ep: 495 | --- | ep_r: -11.9 | step: 349\n",
      "Ep: 496 | --- | ep_r: -77.9 | step: 349\n",
      "Ep: 497 | --- | ep_r: -12.6 | step: 349\n",
      "Ep: 498 | --- | ep_r: 20.1 | step: 349\n",
      "Ep: 499 | --- | ep_r: -60.2 | step: 349\n",
      "Ep: 500 | done | ep_r: 46.2 | step: 66\n",
      "Ep: 501 | --- | ep_r: 16.4 | step: 349\n",
      "Ep: 502 | done | ep_r: 45.8 | step: 60\n",
      "Ep: 503 | --- | ep_r: -32.5 | step: 349\n",
      "Ep: 504 | done | ep_r: 46.9 | step: 66\n",
      "Ep: 505 | --- | ep_r: 216.4 | step: 349\n",
      "Ep: 506 | --- | ep_r: -8.9 | step: 349\n",
      "Ep: 507 | done | ep_r: 44.2 | step: 82\n",
      "Ep: 508 | --- | ep_r: -82.7 | step: 349\n",
      "Ep: 509 | --- | ep_r: -49.7 | step: 349\n",
      "Ep: 510 | --- | ep_r: 58.4 | step: 349\n",
      "Ep: 511 | done | ep_r: -73.5 | step: 344\n",
      "Ep: 512 | --- | ep_r: 291.6 | step: 349\n",
      "Ep: 513 | done | ep_r: 54.2 | step: 76\n",
      "Ep: 514 | --- | ep_r: -63.2 | step: 349\n",
      "Ep: 515 | done | ep_r: 27.3 | step: 92\n",
      "Ep: 516 | --- | ep_r: -58.7 | step: 349\n",
      "Ep: 517 | done | ep_r: 28.8 | step: 190\n",
      "Ep: 518 | done | ep_r: 46.3 | step: 65\n",
      "Ep: 519 | done | ep_r: 39.0 | step: 144\n",
      "Ep: 520 | --- | ep_r: 97.0 | step: 349\n",
      "Ep: 521 | --- | ep_r: 18.5 | step: 349\n",
      "Ep: 522 | --- | ep_r: 182.7 | step: 349\n",
      "Ep: 523 | --- | ep_r: 211.6 | step: 349\n",
      "Ep: 524 | --- | ep_r: -30.8 | step: 349\n",
      "Ep: 525 | done | ep_r: 45.7 | step: 58\n",
      "Ep: 526 | done | ep_r: 48.1 | step: 67\n",
      "Ep: 527 | --- | ep_r: -40.6 | step: 349\n",
      "Ep: 528 | done | ep_r: 114.7 | step: 156\n",
      "Ep: 529 | done | ep_r: 44.1 | step: 75\n",
      "Ep: 530 | --- | ep_r: 13.4 | step: 349\n",
      "Ep: 531 | done | ep_r: 44.8 | step: 63\n",
      "Ep: 532 | --- | ep_r: 277.1 | step: 349\n",
      "Ep: 533 | done | ep_r: 46.0 | step: 65\n",
      "Ep: 534 | done | ep_r: 50.8 | step: 319\n",
      "Ep: 535 | done | ep_r: 204.3 | step: 302\n",
      "Ep: 536 | --- | ep_r: -58.8 | step: 349\n",
      "Ep: 537 | done | ep_r: 96.9 | step: 128\n",
      "Ep: 538 | done | ep_r: 42.5 | step: 104\n",
      "Ep: 539 | done | ep_r: 47.8 | step: 58\n",
      "Ep: 540 | --- | ep_r: 210.8 | step: 349\n",
      "Ep: 541 | --- | ep_r: -32.9 | step: 349\n",
      "Ep: 542 | --- | ep_r: -52.2 | step: 349\n",
      "Ep: 543 | done | ep_r: 50.1 | step: 51\n",
      "Ep: 544 | --- | ep_r: 81.8 | step: 349\n",
      "Ep: 545 | done | ep_r: 41.1 | step: 77\n",
      "Ep: 546 | --- | ep_r: -59.8 | step: 349\n",
      "Ep: 547 | done | ep_r: 44.3 | step: 72\n",
      "Ep: 548 | --- | ep_r: -43.0 | step: 349\n",
      "Ep: 549 | done | ep_r: 38.1 | step: 73\n",
      "Ep: 550 | --- | ep_r: -54.7 | step: 349\n",
      "Ep: 551 | done | ep_r: 36.0 | step: 96\n",
      "Ep: 552 | done | ep_r: 45.2 | step: 72\n",
      "Ep: 553 | done | ep_r: 33.3 | step: 91\n",
      "Ep: 554 | done | ep_r: 47.0 | step: 59\n",
      "Ep: 555 | done | ep_r: 47.4 | step: 61\n",
      "Ep: 556 | done | ep_r: 35.7 | step: 204\n",
      "Ep: 557 | done | ep_r: 48.5 | step: 53\n",
      "Ep: 558 | --- | ep_r: 247.7 | step: 349\n",
      "Ep: 559 | done | ep_r: 48.2 | step: 57\n",
      "Ep: 560 | --- | ep_r: -56.7 | step: 349\n",
      "Ep: 561 | done | ep_r: 48.6 | step: 55\n",
      "Ep: 562 | done | ep_r: 46.0 | step: 88\n",
      "Ep: 563 | done | ep_r: 46.2 | step: 65\n",
      "Ep: 564 | done | ep_r: 48.4 | step: 72\n",
      "Ep: 565 | --- | ep_r: 47.9 | step: 349\n",
      "Ep: 566 | --- | ep_r: 178.3 | step: 349\n",
      "Ep: 567 | done | ep_r: 41.0 | step: 103\n",
      "Ep: 568 | done | ep_r: 45.0 | step: 65\n",
      "Ep: 569 | done | ep_r: 45.2 | step: 67\n",
      "Ep: 570 | --- | ep_r: -49.3 | step: 349\n",
      "Ep: 571 | --- | ep_r: 179.6 | step: 349\n",
      "Ep: 572 | --- | ep_r: -39.8 | step: 349\n",
      "Ep: 573 | done | ep_r: 44.9 | step: 68\n",
      "Ep: 574 | --- | ep_r: 108.9 | step: 349\n",
      "Ep: 575 | --- | ep_r: 248.4 | step: 349\n",
      "Ep: 576 | done | ep_r: 80.5 | step: 181\n",
      "Ep: 577 | done | ep_r: 47.7 | step: 56\n",
      "Ep: 578 | --- | ep_r: 45.6 | step: 349\n",
      "Ep: 579 | --- | ep_r: 279.4 | step: 349\n",
      "Ep: 580 | done | ep_r: 49.3 | step: 56\n",
      "Ep: 581 | done | ep_r: 40.5 | step: 77\n",
      "Ep: 582 | done | ep_r: 45.3 | step: 88\n",
      "Ep: 583 | done | ep_r: 70.3 | step: 110\n",
      "Ep: 584 | done | ep_r: 40.8 | step: 150\n",
      "Ep: 585 | done | ep_r: 44.5 | step: 107\n",
      "Ep: 586 | done | ep_r: 38.6 | step: 83\n",
      "Ep: 587 | --- | ep_r: -33.8 | step: 349\n",
      "Ep: 588 | done | ep_r: 45.6 | step: 69\n",
      "Ep: 589 | done | ep_r: 77.0 | step: 147\n",
      "Ep: 590 | done | ep_r: 83.6 | step: 88\n",
      "Ep: 591 | done | ep_r: 40.9 | step: 77\n",
      "Ep: 592 | done | ep_r: 41.7 | step: 68\n",
      "Ep: 593 | --- | ep_r: 25.1 | step: 349\n",
      "Ep: 594 | done | ep_r: 44.2 | step: 110\n",
      "Ep: 595 | --- | ep_r: -70.3 | step: 349\n",
      "Ep: 596 | --- | ep_r: -39.0 | step: 349\n",
      "Ep: 597 | --- | ep_r: -59.9 | step: 349\n",
      "Ep: 598 | done | ep_r: 47.6 | step: 58\n",
      "Ep: 599 | --- | ep_r: 251.6 | step: 349\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Struggles:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed the robot arm doesn't have an easy translation towards the ball as the ball is moved randomly from one quadrant to another, however; the simulation runs perfectly if the ball is smoothly translated from a quadrant to another in clock-wise or vice-versa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reason? \n",
    "    As Suspected, the agent is learning through its immediate past, which makes it easier to suspect the next position resulting in smooth non-singularity movement. \n",
    "    \n",
    "#### How to tackle this?\n",
    "    Initiating random ball positions and training the model for larger number of epochs as suppose to 600."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
